---
title: "BlogEngine ships its agent graph, daily-logger gets a cleaner, and node-template formalizes decisions"
date: 2026-02-27
tags: ["blogengine", "langgraph", "daily-logger", "node-template", "shell", "adr"]
summary: "BlogEngine merges a 9-node agent graph with JWT auth; daily-logger adds a nightly cleaner; node-template formalizes ADRs and migrates 24 commands to skill directories."
---

27 commits across five repos today. The spread is wide but not unfocused â€” BlogEngine crossed a major threshold, daily-logger got smarter about its own maintenance, node-template grew a real decision-capture system, and shell finished the Carbon polish work from the past two days. Each of these moves in the same direction: the infrastructure around Frame is getting more deliberate.

## What shipped

**BlogEngine â€” Phase B (PR #17):** The biggest single merge of the day. The PR lands a full 9-node LangGraph agent graph, JWT authentication, and file-backed storage. The agent graph is the BlogEngine equivalent of what cv-builder built in its LangGraph migration â€” a structured multi-step pipeline replacing a single-shot generation call. The `GET /api/tools` capability manifest (`9fa8c8f`) gives frame-agent a discovery endpoint: any Frame app can now advertise what tools it exposes. That's the Module Federation mental model applied to agent capabilities, not just UI components. The podcast responder flow and working memory features (`70613ee`) shipped alongside â€” BlogEngine can now maintain context across a session the way cv-builder's Resume Generator maintains thread state.

One important distinction: the `GET /api/tools` endpoint is live and returns a structured response, but frame-agent's routing logic that consumes it is not yet wired. The endpoint exists; the orchestration that acts on it is the next phase of work. These are different things and shouldn't be conflated.

**daily-logger â€” daily-cleaner (PR #8):** A new nightly job (11:00 UTC, runs after the main logger) sweeps active repos for stale documentation and resolved TODO/FIXME comments, validates findings with Claude Opus, and opens PRs for cleanup. Today's follow-up commit (`3fbb23e`) threads the current day's article into that validation as primary context â€” so the cleaner knows what just shipped when it evaluates whether a TODO is still live.

The cleaner is also where we introduced a Claude GitHub comment signature convention (PR #6): all Claude-generated GitHub content ends with `---\n*ðŸ¤– Claude Code*`. Every automated action in the system is now distinguishable from human-authored content at a glance.

The daily-cleaner runs Claude Opus on every active repo nightly. "Active repos" is currently five. The per-run inference cost isn't published here because the numbers aren't yet stable enough to be meaningful â€” but this is a recurring cost with a ceiling that scales linearly with repo count, and it will need a budget cap before Frame reaches 10 active apps. That framing applies to the cleaner the same way it applies to the manual PR review trigger described below.

**node-template â€” ADR/OKR architecture (PR #4):** Five accepted ADRs now live in `decisions/adr/`, with a `decisions/README.md` index maintained by a `/adr publish` subcommand (`a113f72`). The five ADRs are retrospective captures of decisions already in production. The ADR template was previously scoped only to the `plan-feature` skill â€” `72f4a34` promotes it to a shared knowledge file available to any skill. The command migration (`905ce6e`) converted 24 flat `.claude/commands/*.md` files into hierarchical skill directories, each with a `knowledge/` subfolder and optional `scripts/`. That's the same pattern we use for domain knowledge injection into Claude â€” the commands and the knowledge live together.

A gap worth naming: the five existing ADRs are documented in node-template, but the decisions they capture affect all five repos. There is currently no governance model for cross-repo architectural decisions. Who owns an ADR when the decision spans BlogEngine, shell, and frame-agent simultaneously? That question isn't answered yet.

**shell â€” Carbon polish complete (PR #2 and fixes):** Full dark/light mode switching (`657fa04`), Redux `themeSlice` replacing ad-hoc token handling (`6071725`), HomeScreen launcher, sidebar hover states, header centering. The root cause from PR #2 â€” `@carbon/styles/css/styles.css` never imported â€” is now fixed. The Claude Code Review workflow also landed in shell with the missing `pull-requests: write` permission corrected (`5b024b4`).

The shell is not yet live at a public URL. There is no screenshot in this article â€” that's a gap, not an oversight to paper over. The Carbon polish is real; the visual state of the shell should be documented separately with an actual artifact.

## The decisions

**ADRs as versioned prompt context â€” the most important idea that shipped today.** The decision to store ADRs in `decisions/adr/` and make them available to any skill isn't just about human documentation. These files get injected into Claude's context during `/plan-feature`, `/techdebt`, and soon `/adr` itself. The architectural history of the project becomes part of every code generation call.

This reframes what documentation is for in an AI-native codebase. In a traditional codebase, an ADR is a record for future humans. Here, it's a versioned artifact that actively shapes future code generation â€” the reasoning behind past choices constrains and informs the model's next output. That's a qualitatively different relationship between documentation and execution. It's also the discipline this system needs to stay coherent as it grows: without versioned decision context, each Claude call starts from scratch. With it, the system has memory of its own reasoning.

The next two ADRs should be prospective, not retrospective: the ShellAgent routing protocol and the capability manifest contract, written before we build them. The `GET /api/tools` pattern is the obvious first candidate â€” it's already being called a system-wide convention, and right now the contract lives only in one app's implementation, not in a spec.

**Capability manifests over implicit contracts.** The `GET /api/tools` endpoint in BlogEngine is an intentional design choice. When frame-agent needs to route a natural language command to the right app, it needs to know what each app can do. Right now that's discoverable at runtime via HTTP. This is the same problem browsers solved with `manifest.json` â€” you need a machine-readable declaration of what a thing is and what it does before you can orchestrate it.

The analogy is useful but incomplete: `manifest.json` has a published spec. The Frame capability manifest does not. The response shape exists in one implementation. That needs to become an ADR before a second Frame app implements it independently and the two diverge. Every Frame app will eventually expose this endpoint, which means the contract needs to be owned somewhere before "eventually" arrives.

**Cleaner as system hygiene, not afterthought.** The daily-cleaner runs *after* the daily-logger intentionally. The logger captures what happened; the cleaner validates that the codebase reflects what the logs claim. Threading today's article as primary context into the cleaner's validation means the system has a coherent picture of its own state before it decides what's stale.

That's a closed feedback loop with a human-readable artifact at the center: the article is ground truth, the cleaner tests the codebase against it, and any mismatch surfaces as a PR. What makes this more than a cron job with Claude bolted on is the shared context â€” the cleaner isn't running blind pattern-matching on TODO comments, it's evaluating them against a documented record of intent. The gap this doesn't yet close: the cleaner can flag that a TODO is stale, but it can't yet distinguish between "stale because it shipped" and "stale because it was abandoned." That distinction matters for a production eval loop.

**Manual Claude PR review, not automatic.** PR #7 switched the Claude PR review workflow from auto-trigger on every push to `workflow_dispatch` only. The tradeoff is explicit: automatic review on every push adds latency and burns API budget on trivial changes. Manual trigger with posted instructions means a human decides when automated review is worth the cost. That's a cost-of-inference tradeoff, not a capability regression.

## Roadmap pulse

BlogEngine's Phase B merge is the phase unlock we needed. With the agent graph running, JWT auth gating the API, and the capability manifest endpoint live, BlogEngine is structurally equivalent to cv-builder's backend: a LangGraph pipeline behind a protected Express API, registered as a Module Federation remote. Phase 9 â€” daily-logger articles publishing to BlogEngine â€” is now unblocked on the BlogEngine side. The remaining work is on the daily-logger side: the POST pipeline that takes a finalized article and submits it through BlogEngine's agent graph rather than committing directly to the repo.

Shell's Carbon work is done. The next shell commit should be Phase 3: the header chat command bar. The HomeScreen launcher that shipped today is a static list of app tiles; the roadmap version launches app instances from a natural language command interpreted by ShellAgent.

node-template's ADR system gives us something we didn't have before: a place to formally record the decisions that have been made implicitly across five repos. The five existing ADRs are retrospective â€” they document decisions already in production. The next ADRs should be prospective: capture the ShellAgent routing protocol and the capability manifest contract before we build them, not after.

## What's next

Wire daily-logger's POST pipeline to BlogEngine's agent graph â€” the first end-to-end test of a Frame app consuming output from another Frame app through the shared shell. This is the demo moment: daily-logger generates an article, POST pipeline submits it to BlogEngine's agent graph, BlogEngine processes and stores it, shell surfaces it. That sequence, working end-to-end, is the first time two Frame apps talk to each other through the shell. It should be built and demoed as such, not just verified as a data flow.

---

*Generated by [daily-logger](https://github.com/ojfbot/daily-logger) â€” part of the ojfbot self-documenting development system.*
