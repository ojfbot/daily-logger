---
title: "cv-builder's visual regression loop closes its first issue: what PR #93 actually built"
date: 2026-02-24
tags: ["cv-builder", "visual-regression", "ci-cd", "draw-io", "s3", "eval-loop"]
summary: "PR #93 closes issue #90 and completes ~70% of Phase 6 — here's what the CanvasRunNavigator pipeline actually does and what's missing."
---

54 commits across three repos today, with the bulk of the weight in cv-builder. The headline is PR #93 merging — the Interactive Draw.io Canvas Viewer — which closes issue #90 and represents the most complete single feature shipped on the visual regression front. But the commit history tells a more honest story: 30+ fixes iterating on the same feature before it merged. That iteration pattern is the point — and the failures it surfaced are the actual proof-of-value for this loop.

## What shipped

PR #93 delivers `CanvasRunNavigator` — a CI-aware thumbnail navigator that replaces the placeholder `DiagramViewer` in the cv-builder dashboard. The pipeline it connects to:

1. Playwright captures screenshots of cv-builder UI routes during CI
2. pixelmatch compares each screenshot against the stored baseline
3. Side-by-side baseline vs. actual images get RED/GREEN frames added — green border for pass, red border for fail, applied directly to the image so the diff is readable without any additional tooling
4. Thumbnails upload to S3
5. A Python script writes a PR comment table with screenshot thumbnails inline and a GitHub Pages link for the full run
6. draw.io canvas embeds the screenshots, one slot per run, navigable by run number

The PR comment and the draw.io canvas are two surfaces for the same data, consuming it differently. The PR comment gives reviewers immediate visual context without leaving GitHub — it's ephemeral, scoped to the review moment. The draw.io canvas gives a persistent, browsable record of what the UI looked like across runs — which is what issue #94 (multi-run comparison + diff timeline) will extend by appending rather than overwriting on each CI run.

The audience for the canvas right now is a single developer and, eventually, the ShellAgent querying run history programmatically. That's an honest answer to why draw.io XML brittleness is an acceptable tradeoff today — there's no team depending on this surface yet — and it's also the exit criterion: once the ShellAgent needs to query structured run data reliably, the XML manipulation model breaks down and a proper artifact store replaces it.

**What the CI loop caught before PR #93 merged:**

| Commit | Failure category | What would have shipped without it |
|--------|-----------------|------------------------------------|
| `4ca68d1` | Route path field mismatch + screenshot directory misconfiguration | Screenshots captured to wrong paths, pipeline silently producing no output |
| `5000af9` | Playwright writing actuals to wrong path; missing `data-element` selectors | pixelmatch comparing against stale baselines, false-pass on every route |
| `7701c43` | Workflow permission scope bleed; non-unique draw.io canvas node IDs | S3 job with GitHub Pages write access; visual corruption on run 2+ |
| `cc56c6f` | TruffleHog false-positive on main push; blog-post-proposer false trigger | Secret scanner blocking every main merge; proposer firing on unrelated events |
| `050d776` | Zod v4 `z.record` schema crash | Runtime failure on tool capability validation, ShellAgent interface broken at startup |

Five commits, six distinct failure categories, all caught by the CI loop itself running against real output before the feature reached reviewers. That's the proof of value for the eval loop concept: not that it's clean, but that it finds real failures in real infrastructure before they compound.

daily-logger also shipped two meaningful commits: `8db86f5` adds shell and daily-logger to the repo sweep (both repos now appear in the commit feed that generates this article), and `080011f` introduces a draft PR editorial workflow with a split GitHub Pages deploy. The sweep expansion matters — this article exists because those repos were included.

## The decisions

**Why draw.io for visual history.** The alternative was a custom React dashboard tracking run state in a database. draw.io gives a free, editable, embeddable canvas that CI writes to via XML — no backend, no schema migrations, no auth layer. The tradeoff is that draw.io's data model is XML manipulation, which is brittle at scale. `7701c43` hit the deduplication edge case on the first real cycle: CI was generating non-unique IDs for canvas nodes, causing visual corruption on run 2+.

The brittleness was accepted deliberately. The goal right now is a working eval loop, not a production-grade observability platform. The exit criterion is clear: when the ShellAgent (or a future contributor) needs to query structured run history reliably, XML manipulation breaks down and gets replaced — most likely with an S3-hosted static JSON feed rendering run history, which preserves the no-backend constraint while giving a queryable data structure. That decision and its tradeoffs belong in an ADR in the repo, not just here. That's a gap worth closing.

One open cost question: S3 storage and GitHub Actions minutes accumulate as screenshot artifacts pile up across runs. At current CI frequency the cost is negligible. At 50+ runs/week it needs modeling. No estimate exists yet — that's an honest gap.

**Least-privilege CI in `7701c43`.** The visual regression workflow had accumulated too many permissions in a single job. Splitting them means the S3 upload job can't write to GitHub Pages, and the Pages deploy job can't access AWS credentials. This is access scoping applied to CI rather than to agent actions — the same principle that makes tool-use trustworthy in an agent system applies to automated pipelines writing to production surfaces.

**`GET /api/tools` capability manifest in `f2987e5`.** Exposes what tools an agent can use as a first-class API endpoint. Nothing is consuming this endpoint today — it's speculative infrastructure. The justification is that when the ShellAgent arrives, it can query cv-builder's capabilities programmatically rather than having them hardcoded. The response shape is a flat JSON array of tool descriptors: `{ name, description, inputSchema }` per tool, matching the MCP tool manifest format. Whether that's the right interface contract is a question Phase 3 will answer — but the endpoint exists and is versioned.

## Roadmap pulse

Phase 6 (visual regression) is at roughly 70%. The remaining 30% is two issues: issue #94 (multi-run canvas comparison — run N vs. run N-1 delta highlighting, so reviewers see not just whether a screenshot changed but by how much and where) and issue #91 (navigable UI flow tree with screenshot links — a structural view of the route graph with screenshots attached to each node, rather than a flat thumbnail list). Those two issues are the denominator for that percentage. If there's scope beyond them, it hasn't been surfaced yet.

Phase 9 (daily-logger articles publishing to BlogEngine) got a dependency resolved today: the repo sweep now includes daily-logger, so the system is aware of its own commits. That closes a circular awareness gap present since BlogEngine was defined.

## What's next

Issue #94 is the concrete next action: implement run-history tracking and diff timeline in the draw.io canvas so each new CI run appends rather than overwrites, and the delta between runs is visually surfaced in the PR comment. That's also when the draw.io XML model gets its second stress test — if the append logic surfaces more deduplication failures, that's the signal to evaluate the static JSON feed replacement.

The ADR for the draw.io decision should be written before issue #94 starts. The reasoning exists; it just needs to live where the code lives.

---

*Generated by [daily-logger](https://github.com/ojfbot/daily-logger) — part of the ojfbot self-documenting development system.*
